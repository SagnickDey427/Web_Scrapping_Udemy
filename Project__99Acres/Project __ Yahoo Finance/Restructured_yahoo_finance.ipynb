{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f526d9f-f763-447d-96f6-c0db3db222f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraper.py\n",
    "\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "\n",
    "class YahooFinanceScraper:\n",
    "    def __init__(self):\n",
    "        # Initialize the Chrome driver\n",
    "        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "        self.driver.maximize_window()\n",
    "        self.wait = WebDriverWait(self.driver, 10)\n",
    "        self.actions = ActionChains(self.driver)\n",
    "        self.data = []\n",
    "\n",
    "    def wait_to_load(self):\n",
    "        try:\n",
    "            self.wait.until(lambda d: d.execute_script(\"return document.readyState\") == \"complete\")\n",
    "        except Exception as e:\n",
    "            print(\"Page didn't load fully within time limit. Error:\", e)\n",
    "        else:\n",
    "            print(\"Page\", self.driver.title, \"loaded successfully!\")\n",
    "\n",
    "    def scrape_data(self):\n",
    "        url = \"https://finance.yahoo.com/\"\n",
    "        self.driver.get(url)\n",
    "        self.wait_to_load()\n",
    "\n",
    "        # Hover over 'Market' menu\n",
    "        market_menu = self.wait.until(\n",
    "            EC.presence_of_element_located((By.XPATH,  '/html[1]/body[1]/div[2]/header[1]/div[1]/div[1]/div[1]/div[4]/div[1]/div[1]/ul[1]/li[3]/a[1]/span[1]'))\n",
    "        )\n",
    "        self.actions.move_to_element(market_menu).perform()\n",
    "\n",
    "        # Click 'Trending Tickers'\n",
    "        trending_tickers = self.wait.until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//div[contains(text(),'Trending Tickers')]\"))\n",
    "        )\n",
    "        trending_tickers.click()\n",
    "        self.wait_to_load()\n",
    "\n",
    "        # Click 'Most Active'\n",
    "        most_active = self.wait.until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//span[normalize-space()='Most Active']\"))\n",
    "        )\n",
    "        most_active.click()\n",
    "        self.wait_to_load()\n",
    "\n",
    "        # Scrape table rows across all pages\n",
    "        while True:\n",
    "            self.wait.until(EC.presence_of_element_located((By.TAG_NAME, \"table\")))\n",
    "            rows = self.driver.find_elements(By.CSS_SELECTOR, \"table tbody tr\")\n",
    "            for row in rows:\n",
    "                values = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                if len(values) >= 10:\n",
    "                    stock = {\n",
    "                        \"Name\": values[1].text,\n",
    "                        \"Symbol\": values[0].text,\n",
    "                        \"Price\": values[3].text,\n",
    "                        \"Change\": values[4].text,\n",
    "                        \"Volume\": values[6].text,\n",
    "                        \"Market cap\": values[8].text,\n",
    "                        \"PE_ratio\": values[9].text\n",
    "                    }\n",
    "                    self.data.append(stock)\n",
    "\n",
    "            try:\n",
    "                next_btn = self.wait.until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//button[@aria-label='Goto next page']\"))\n",
    "                )\n",
    "                if next_btn.get_attribute(\"disabled\") is not None:\n",
    "                    print(\"Next button is disabled. Reached last page.\")\n",
    "                    break\n",
    "                self.actions.move_to_element(next_btn).click().perform()\n",
    "                time.sleep(2)\n",
    "            except:\n",
    "                print(\"No more pages or error while clicking next.\")\n",
    "                break\n",
    "\n",
    "        self.driver.quit()\n",
    "        return self.data\n",
    "\n",
    "    def clean_data(self):\n",
    "        df = pd.DataFrame(self.data)\n",
    "\n",
    "        df = df.apply(lambda col: col.str.strip() if col.dtype == \"object\" else col).rename(\n",
    "            columns={\"Price\": \"Price_usd\"}\n",
    "        )\n",
    "\n",
    "        # Price & Change to numeric\n",
    "        df = df.assign(\n",
    "            Price_usd=lambda d: pd.to_numeric(d.Price_usd),\n",
    "            Change=lambda d: pd.to_numeric(d.Change.astype(str).str.replace(\"+\", \"\", regex=False))\n",
    "        )\n",
    "\n",
    "        # Volume cleanup\n",
    "        df = df.assign(\n",
    "            Volume=lambda d: pd.to_numeric(d.Volume.astype(str).str.replace(\",\", \"\").str.replace(\"M\", \"\"))\n",
    "        ).rename(columns={\"Volume\": \"Volume_in_M\"})\n",
    "\n",
    "        # Market Cap cleanup\n",
    "        def convert_market_cap_to_billion(col):\n",
    "            col = col.str.strip()\n",
    "            number = pd.to_numeric(col.str[:-1], errors=\"coerce\")\n",
    "            suffix = col.str[-1]\n",
    "            scale_map = {\"M\": 1 / 1000, \"B\": 1, \"T\": 1000}\n",
    "            scale = suffix.map(scale_map)\n",
    "            return number * scale\n",
    "\n",
    "        df = df.rename(columns={\"Market cap\": \"Market_cap\"}).assign(\n",
    "            Market_cap_in_B=lambda d: convert_market_cap_to_billion(d[\"Market_cap\"])\n",
    "        ).drop(columns=[\"Market_cap\"])\n",
    "\n",
    "        # PE_ratio cleanup\n",
    "        df = df.assign(\n",
    "            PE_ratio=lambda d: d.PE_ratio.str.strip().replace(\"--\", np.nan).str.replace(\",\", \"\")\n",
    "        ).assign(\n",
    "            PE_ratio=lambda d: pd.to_numeric(d.PE_ratio)\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b2c0277-0f66-4efe-8c17-9ae921b3bdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Yahoo Finance - Stock Market Live, Quotes, Business & Finance News loaded successfully!\n",
      "Page Yahoo Finance - Stock Market Live, Quotes, Business & Finance News loaded successfully!\n",
      "Page Top Trending Stocks: US stocks with the highest interest today - Yahoo Finance loaded successfully!\n",
      "No more pages or error while clicking next.\n",
      "Data saved to Yahoo_Stocks_restruc.csv\n"
     ]
    }
   ],
   "source": [
    "scraper = YahooFinanceScraper()\n",
    "\n",
    "# Step 1: Scrape\n",
    "raw_data = scraper.scrape_data()\n",
    "\n",
    "# Step 2: Clean\n",
    "cleaned_df = scraper.clean_data()\n",
    "\n",
    "# Save to CSV\n",
    "cleaned_df.to_csv(\"Yahoo_Stocks_restruc.csv\", index=False)\n",
    "print(\"Data saved to Yahoo_Stocks_restruc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287854d0-0369-4fdc-943b-8cf4a06bdaf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Web Scrapping Udemy",
   "language": "python",
   "name": "web_scrapping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
