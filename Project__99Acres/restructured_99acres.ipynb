{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e95cf94-923e-48c5-85ac-8e5fbf95b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "class PropertyScraper99Acres:\n",
    "    def __init__(self, city=\"Chennai\"):\n",
    "        self.city = city\n",
    "        self.data = []\n",
    "\n",
    "        # Set Chrome options\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--disable-http2\")\n",
    "        chrome_options.add_argument(\"--incognito\")\n",
    "        chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "        chrome_options.add_argument(\"--ignore-certificate-errors\")\n",
    "        chrome_options.add_argument(\"--enable-features=NetworkServiceInProcess\")\n",
    "        chrome_options.add_argument(\"--disable-features=NetworkService\")\n",
    "        chrome_options.add_argument(\n",
    "            \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "            \"(KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36\"\n",
    "        )\n",
    "\n",
    "        # Launch driver\n",
    "        self.driver = webdriver.Chrome(\n",
    "            service=Service(ChromeDriverManager().install()),\n",
    "            options=chrome_options\n",
    "        )\n",
    "        self.wait = WebDriverWait(self.driver, 10)\n",
    "        self.actions = ActionChains(self.driver)\n",
    "\n",
    "    def wait_to_load(self):\n",
    "        try:\n",
    "            self.wait.until(lambda d: d.execute_script(\"return document.readyState\") == \"complete\")\n",
    "        except Exception as e:\n",
    "            print(\"Page load timeout:\", e)\n",
    "        else:\n",
    "            print(\"Page loaded successfully:\", self.driver.title)\n",
    "\n",
    "    def scrape_properties(self):\n",
    "        url = \"https://www.99acres.com/\"\n",
    "        self.driver.get(url)\n",
    "        self.wait_to_load()\n",
    "\n",
    "        # Interact with search bar\n",
    "        try:\n",
    "            search_bar = self.wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"keyword2\"]')))\n",
    "            search_bar.send_keys(self.city)\n",
    "            time.sleep(2)\n",
    "            valid_option = self.wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"0\"]')))\n",
    "            valid_option.click()\n",
    "            time.sleep(2)\n",
    "            search_btn = self.wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"searchform_search_btn\"]')))\n",
    "            search_btn.click()\n",
    "            self.wait_to_load()\n",
    "        except Exception as e:\n",
    "            print(\"Error during search setup:\", e)\n",
    "\n",
    "        # Filters\n",
    "        try:\n",
    "            slider = self.wait.until(EC.element_to_be_clickable((By.ID, \"budgetLeftFilter_max_node\")))\n",
    "            self.actions.click_and_hold(slider).move_by_offset(-73, 0).release().perform()\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            print(\"Couldn't adjust budget slider.\")\n",
    "\n",
    "        for tag in [\"Verified\", \"Ready To Move\", \"With Photos\", \"With Videos\"]:\n",
    "            try:\n",
    "                tag_elem = self.wait.until(EC.element_to_be_clickable((By.XPATH, f\"//span[normalize-space()='{tag}']\")))\n",
    "                tag_elem.click()\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                print(f\"Tag '{tag}' could not be clicked.\")\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                self.extract_page_data()\n",
    "                next_btn = self.wait.until(EC.element_to_be_clickable((By.XPATH, \"//a[normalize-space()='Next Page >']\")))\n",
    "                self.driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_btn)\n",
    "                time.sleep(2)\n",
    "                next_btn.click()\n",
    "                time.sleep(5)\n",
    "            except:\n",
    "                print(\"No more pages or error while navigating.\")\n",
    "                break\n",
    "\n",
    "        self.driver.quit()\n",
    "        return self.data\n",
    "\n",
    "    def extract_page_data(self):\n",
    "        rows = self.driver.find_elements(By.CLASS_NAME, \"tupleNew__TupleContent\")\n",
    "        for row in rows:\n",
    "            def try_extract(by, class_name):\n",
    "                try:\n",
    "                    return row.find_element(by, class_name).text\n",
    "                except:\n",
    "                    return np.nan\n",
    "\n",
    "            name = try_extract(By.CLASS_NAME, \"tupleNew__headingNrera\")\n",
    "            location = try_extract(By.CLASS_NAME, \"tupleNew__propType\")\n",
    "            price = try_extract(By.CLASS_NAME, \"tupleNew__priceValWrap\")\n",
    "\n",
    "            try:\n",
    "                elements = row.find_elements(By.CLASS_NAME, \"tupleNew__area1Type\")\n",
    "                area, bhk = [ele.text for ele in elements] if len(elements) == 2 else [np.nan, np.nan]\n",
    "            except:\n",
    "                area, bhk = [np.nan, np.nan]\n",
    "\n",
    "            self.data.append({\n",
    "                \"name\": name,\n",
    "                \"location\": location,\n",
    "                \"price\": price,\n",
    "                \"area\": area,\n",
    "                \"bhk\": bhk\n",
    "            })\n",
    "\n",
    "    def clean_data(self):\n",
    "        df = pd.DataFrame(self.data).drop_duplicates()\n",
    "\n",
    "        def convert_price(val):\n",
    "            val = val.replace(\"â‚¹\", \"\").strip().lower()\n",
    "            if \"lac\" in val:\n",
    "                return float(val.replace(\"lac\", \"\").strip())\n",
    "            elif \"cr\" in val:\n",
    "                return float(val.replace(\"cr\", \"\").strip()) * 100\n",
    "            return np.nan\n",
    "\n",
    "        return (\n",
    "            df\n",
    "            .apply(lambda col: col.str.strip().str.lower() if col.dtype == \"object\" else col)\n",
    "            .assign(\n",
    "                is_starred=lambda df_: df_.name.str.contains(\"\\n\").astype(int),\n",
    "                name=lambda df_: (\n",
    "                    df_.name.str.replace(\"\\n[0-9.]+\", \"\", regex=True)\n",
    "                           .str.strip()\n",
    "                           .replace(\"adroit district s\", \"adroit district's\")\n",
    "                ),\n",
    "                location=lambda df_: (\n",
    "                    df_.location.str.replace(\"chennai\", \"\")\n",
    "                                .str.strip()\n",
    "                                .str.replace(\",$\", \"\", regex=True)\n",
    "                                .str.split(\"in\")\n",
    "                                .str[-1]\n",
    "                                .str.strip()\n",
    "                ),\n",
    "                price=lambda df_: df_.price.apply(convert_price),\n",
    "                area_sqft=lambda df_: pd.to_numeric(\n",
    "                    df_.area.str.replace(\"sqft\", \"\").str.replace(\",\", \"\").str.strip()\n",
    "                ),\n",
    "                bhk=lambda df_: pd.to_numeric(\n",
    "                    df_.bhk.str.replace(\"bhk\", \"\").str.strip()\n",
    "                )\n",
    "            )\n",
    "            .drop(columns=[\"area\", \"bhk\"])\n",
    "            .rename(columns={\"price\": \"price_lakhs\"})\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2be47e58-3007-4a7f-bc43-725c584c3608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page loaded successfully: India Real Estate Property Site - Buy Sell Rent Properties Portal - 99acres.com\n",
      "Page loaded successfully: Property in Chennai - Real Estate in Chennai\n",
      "Tag 'With Videos' could not be clicked.\n",
      "No more pages or error while navigating.\n",
      "Data saved to chennai-properties-99acres.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    scraper = PropertyScraper99Acres(city=\"Chennai\")\n",
    "    \n",
    "    # Step 1: Scrape\n",
    "    raw_data = scraper.scrape_properties()\n",
    "\n",
    "    # Step 2: Clean\n",
    "    cleaned_df = scraper.clean_data()\n",
    "\n",
    "    # Save to CSV\n",
    "    cleaned_df.to_excel(\"chennai-properties-99acres.xlxx\", index=False)\n",
    "    print(\"Data saved to chennai-properties-99acres.xlxx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e52e4-4417-4502-b59d-9a75eccc2380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Web Scrapping Udemy",
   "language": "python",
   "name": "web_scrapping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
